{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 0.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print 'TensorFlow version:', tf.__version__\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Level RNN on Startup Quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by [@karpathy](https://github.com/karpathy)'s char-rnn but written in TensorFlow.\n",
    "\n",
    "In this example notebook we will be training on startup quotes sourced from this tsv: https://github.com/startuptxt/startuptxt.github.io/blob/master/quotes.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('./quotes.tsv', 'rU')\n",
    "lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If you want to teach people a new way of thinking, don\\xe2\\x80\\x99t bother trying to teach them. Instead, give them a tool, the use of which will lead to new ways of thinking.', 'When I am working on a problem, I never think about beauty\\xe2\\x80\\xa6\\xe2\\x80\\xa6.. but when I have finished, if the solution is not beautiful, I know it is wrong.', 'Humans beings always do the most intelligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve tried every stupid alternative and none of them have worked.', 'I just invent, then wait until man comes around to needing what I\\xe2\\x80\\x99ve invented.', 'I\\xe2\\x80\\x99m not a genius. I\\xe2\\x80\\x99m just a tremendous bundle of experience.']\n"
     ]
    }
   ],
   "source": [
    "quotes = [line.split('\\t')[0] for line in lines]\n",
    "print quotes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_input_string = '\\n'.join(quotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding for each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<type 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create one-hot mapping by tricking sklearn's DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "v = DictVectorizer(sparse=False)\n",
    "unique_chars = set(raw_input_string)\n",
    "# Build a dict that looks like [{'a':1}, {'b':1}, {'c':1}, ...]\n",
    "D = [{char:1} for char in unique_chars]\n",
    "# \n",
    "v.fit(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode_string(string):\n",
    "    out = []\n",
    "    for char in string:\n",
    "        vec = v.transform({char: 1})[0]\n",
    "        out.append(vec) # returns the one-hot array associated with the character\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_enc = encode_string(\"If you\\nwant\")\n",
    "# The string \"If\" after one-hot encoding\n",
    "example_enc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 91)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_string(string):\n",
    "    out = []\n",
    "    for char in string:\n",
    "        char_dict = v.inverse_transform(char.reshape(1, -1))[0] # returns the dict associated with the character e.g. {'I': 1}\n",
    "        out += char_dict.keys()[0] # append the key, which is the character we want e.g. 'I'\n",
    "    return ''.join(out) # join the characters together to form the decoded string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If you\\nwant'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_string(example_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs and Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 10000\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_input = len(unique_chars) # Length of one-hot encoded vectors i.e. which is also the number of unique characters\n",
    "n_output = n_input # The characters we feed the NN are the same characters it will be outputting\n",
    "n_steps = 100 # Number of previous characters to look at\n",
    "n_hidden = 200 # Number of nodes in each hidden layer\n",
    "n_layers = 3 # Number of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_output])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_output]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a lstm cell with tensorflow\n",
    "cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "cell = tf.nn.rnn_cell.MultiRNNCell([cell] * n_layers, state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get lstm cell outputs\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32)\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "last = tf.gather(outputs, int(outputs.get_shape()[0]) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Linear activation, using rnn inner loop last output\n",
    "pred = tf.matmul(last, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start our tensorflow session\n",
    "sess = tf.Session()\n",
    "# initialize the varsriables we defined above\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a function that outputs two arrays:\n",
    "# 1. batch_x - an array with shape (n, t, m) where n=batch_size, t=number of characters aka time-steps, and m=length of one-hot character vector\n",
    "# 2. batch_y - an array with shape (n, m) where n=batch_size and m=length one-hot character vector\n",
    "def next_batch(string, batch_size=75, n_steps=50):\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    i_ys = np.random.randint(n_steps, len(string), size=batch_size) # e.g. i_ys=np.array([25, 50, 75])\n",
    "    for i_y in i_ys:\n",
    "        i_x_end = i_y # e.g. i_x_end = i_y = 25\n",
    "        if i_x_end-n_steps < 0:\n",
    "            i_x_start = 0 # e.g. i_start = 0\n",
    "        else:\n",
    "            i_x_start = i_x_end-n_steps\n",
    "        string_x = string[i_x_start:i_x_end] # e.g. string[0:25]\n",
    "        string_y = string[i_y] # e.g. string[25]\n",
    "        vec_x = encode_string(string_x)\n",
    "        vec_y = encode_string(string_y)\n",
    "        batch_x.append(vec_x)\n",
    "        batch_y.append(vec_y[0])\n",
    "    return np.array(batch_x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 75, 91)\n",
      "' strategic moves or their intuitive business sense or a variety of other se'\n",
      "(1, 91)\n",
      "'l'\n"
     ]
    }
   ],
   "source": [
    "# Test the next_batch function\n",
    "batch_x, batch_y = next_batch(raw_input_string, 1, 75)\n",
    "print batch_x.shape\n",
    "print repr(decode_string(batch_x[0]))\n",
    "print batch_y.shape\n",
    "print repr(decode_string(batch_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [39:09<00:00,  4.25it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(training_iters)):\n",
    "#for i in range(training_iters):\n",
    "    # Get the next batch of training data\n",
    "    batch_x, batch_y = next_batch(raw_input_string, batch_size, n_steps)\n",
    "    # Run optimization op (backprop)\n",
    "    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y = next_batch(raw_input_string, 250, n_steps)\n",
    "print \"Testing Accuracy:\", \\\n",
    "    sess.run(accuracy, feed_dict={x: test_x, y: test_y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict some Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_chars = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op_pred_char = tf.argmax(pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' in business is not to think too much about making it.\\nIn the long run people are going to buy the c'\n"
     ]
    }
   ],
   "source": [
    "# Build initial seed string\n",
    "i = np.random.randint(0, 5000)\n",
    "seed_string = raw_input_string[i:(i+n_steps)]\n",
    "print repr(seed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:34<00:00, 28.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in business is not to think too much about making it.\n",
      "In the long run people are going to buy the company is that the right is to start to get things.\n",
      "I think it is a beginning; I took a simple by dousn’t make a lot of progress.\n",
      "People don’t need to be brilliant to start a business and a team to be a successful entrepreneurship are doing about the problem or now to start the inside than entrepreneurship is a good jobking and are against the first step.\n",
      "The best time to be a waser drises—that is work.\n",
      "I think a lot of with the small. No big things in the world.\n",
      "I think a business a special and destrobted to accomplish a something, and that’s a successful entrepreneurship are doing about the problem or now to start the inside than entrepreneurship is a good jobking and are against the first step.\n",
      "The best time to be a waser drises—that is work.\n",
      "I think a lot of with the small. No big things in the world.\n",
      "I think a business a special and destrobted to accomplish a something, and that’s a successful entrepreneurship are doing about the problem or now to start the inside than\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop throught the following steps:\n",
    "# 1. Grab the last t characters\n",
    "# 2. Predict and append the next letter\n",
    "# 3. Repeat steps 1-2 until the limit is reached\n",
    "for i in tqdm(range(n_chars)):\n",
    "    # Encode last t characters of seed string\n",
    "    new_seed = seed_string[-n_steps:]\n",
    "    enc_seed = np.array([encode_string(new_seed)]) # transform into shape=[1, 50, 91]\n",
    "\n",
    "    # Predict using seed string\n",
    "    pred_index = op_pred_char.eval(feed_dict={x:enc_seed}, session=sess)\n",
    "    char_vec = np.zeros([1, enc_seed.shape[2]])\n",
    "    char_vec[0][pred_index] = 1\n",
    "    pred_char = decode_string(char_vec)\n",
    "    \n",
    "    # Print last 50 chars and predicted char\n",
    "    #print \"{}, {}\".format(repr(new_seed), repr(pred_char))\n",
    "\n",
    "    # Decode and append the character to the end of the seed string\n",
    "    seed_string+=pred_char\n",
    "    \n",
    "# What's the final string?\n",
    "print seed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
