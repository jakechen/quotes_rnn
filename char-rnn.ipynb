{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 0.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print 'TensorFlow version:', tf.__version__\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Level RNN on Startup Quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by [@karpathy](https://github.com/karpathy)'s char-rnn but written in TensorFlow.\n",
    "\n",
    "In this example notebook we will be training on startup quotes sourced from this tsv: https://github.com/startuptxt/startuptxt.github.io/blob/master/quotes.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('./quotes.tsv', 'rU')\n",
    "lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If you want to teach people a new way of thinking, don\\xe2\\x80\\x99t bother trying to teach them. Instead, give them a tool, the use of which will lead to new ways of thinking.', 'When I am working on a problem, I never think about beauty\\xe2\\x80\\xa6\\xe2\\x80\\xa6.. but when I have finished, if the solution is not beautiful, I know it is wrong.', 'Humans beings always do the most intelligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve tried every stupid alternative and none of them have worked.', 'I just invent, then wait until man comes around to needing what I\\xe2\\x80\\x99ve invented.', 'I\\xe2\\x80\\x99m not a genius. I\\xe2\\x80\\x99m just a tremendous bundle of experience.']\n"
     ]
    }
   ],
   "source": [
    "quotes = [line.split('\\t')[0] for line in lines]\n",
    "print quotes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_input_string = '\\n'.join(quotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding for each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<type 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create one-hot mapping by tricking sklearn's DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "v = DictVectorizer(sparse=False)\n",
    "unique_chars = set(raw_input_string)\n",
    "# Build a dict that looks like [{'a':1}, {'b':1}, {'c':1}, ...]\n",
    "D = [{char:1} for char in unique_chars]\n",
    "# \n",
    "v.fit(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode_string(string):\n",
    "    out = []\n",
    "    for char in string:\n",
    "        vec = v.transform({char: 1})[0]\n",
    "        out.append(vec) # returns the one-hot array associated with the character\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_enc = encode_string(\"If you\\nwant\")\n",
    "# The string \"If\" after one-hot encoding\n",
    "example_enc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_string(string):\n",
    "    out = []\n",
    "    for char in string:\n",
    "        char_dict = v.inverse_transform(char.reshape(1, -1))[0] # returns the dict associated with the character e.g. {'I': 1}\n",
    "        out += char_dict.keys()[0] # append the key, which is the character we want e.g. 'I'\n",
    "    return ''.join(out) # join the characters together to form the decoded string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If you\\nwant'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_string(example_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs and Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 5000\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_input = len(unique_chars) # Length of one-hot encoded vectors i.e. which is also the number of unique characters\n",
    "n_output = n_input # The characters we feed the NN are the same characters it will be outputting\n",
    "n_steps = 50 # Number of previous characters to look at\n",
    "n_hidden = 100 # Number of nodes in each hidden layer\n",
    "n_layers = 1 # Number of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_output])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_output]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a lstm cell with tensorflow\n",
    "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "#cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * n_layers, state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get lstm cell outputs\n",
    "outputs, states = tf.nn.dynamic_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "last = tf.gather(outputs, int(outputs.get_shape()[0]) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Linear activation, using rnn inner loop last output\n",
    "pred = tf.matmul(last, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start our tensorflow session\n",
    "sess = tf.Session()\n",
    "# initialize the varsriables we defined above\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a function that outputs two arrays:\n",
    "# 1. batch_x - an array with shape (n, t, m) where n=batch_size, t=number of characters aka time-steps, and m=length of one-hot character vector\n",
    "# 2. batch_y - an array with shape (n, m) where n=batch_size and m=length one-hot character vector\n",
    "def next_batch(string, batch_size=75, n_steps=50):\n",
    "    batch_x = []\n",
    "    batch_y = []\n",
    "    i_ys = np.random.randint((n_steps+1), len(string), size=batch_size)\n",
    "    for i_y in i_ys:\n",
    "        i_x_end = i_y-1\n",
    "        if i_x_end-n_steps < 0:\n",
    "            i_x_start = 0\n",
    "        else:\n",
    "            i_x_start = i_x_end-n_steps\n",
    "        string_x = string[i_x_start:i_x_end]\n",
    "        string_y = string[i_y]\n",
    "        vec_x = encode_string(string_x)\n",
    "        vec_y = encode_string(string_y)\n",
    "        batch_x.append(vec_x)\n",
    "        batch_y.append(vec_y[0])\n",
    "    return np.array(batch_x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m not'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x, batch_y = next_batch(raw_input_string, 5, 5)\n",
    "\n",
    "decode_string(batch_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [15:07<00:00,  2.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(training_iters)):\n",
    "#for i in range(training_iters):\n",
    "    # Get the next batch of training data\n",
    "    batch_x, batch_y = next_batch(raw_input_string, batch_size, n_steps)\n",
    "    # Run optimization op (backprop)\n",
    "    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.268\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y = next_batch(raw_input_string, 250, n_steps)\n",
    "print \"Testing Accuracy:\", \\\n",
    "    sess.run(accuracy, feed_dict={x: test_x, y: test_y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict some Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_chars = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op_pred_char = tf.argmax(pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'o the most intelligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve tri', 'g'\n",
      "' the most intelligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig', ' '\n",
      "'the most intelligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig ', 'o'\n",
      "'he most intelligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o', ' '\n",
      "'e most intelligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ', 'a'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [00:00<00:01, 77.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' most intelligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o a', 'd'\n",
      "'most intelligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad', ' '\n",
      "'ost intelligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad ', 'o'\n",
      "'st intelligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o', ' '\n",
      "'t intelligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ', 'a'\n",
      "' intelligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o a', 'd'\n",
      "'intelligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad', ' '\n",
      "'ntelligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad ', 'o'\n",
      "'telligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o', ' '\n",
      "'elligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o ', 'a'\n",
      "'lligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o a', 'd'\n",
      "'ligent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o ad', ' '\n",
      "'igent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o ad ', 'o'\n",
      "'gent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o ad o', ' '\n",
      "'ent thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o ad o ', 'a'\n",
      "'nt thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o ad o a', 'd'\n",
      "'t thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad', ' '\n",
      "' thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad ', 'o'\n",
      "'thing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o', ' '\n",
      "'hing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ', 'a'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [00:00<00:00, 68.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ing\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o a', 'd'\n",
      "'ng\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ad', ' '\n",
      "'g\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ad ', 'o'\n",
      "'\\xe2\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ad o', ' '\n",
      "'\\x80\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ad o ', 'a'\n",
      "'\\xa6after they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ad o a', 'd'\n",
      "'after they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ad o ad', ' '\n",
      "'fter they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ad o ad ', 'o'\n",
      "'ter they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ad o ad o', ' '\n",
      "'er they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ad o ad o ', 'a'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [00:00<00:00, 61.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'r they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ad o ad o a', 'd'\n",
      "' they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ad o ad o ad', ' '\n",
      "'they\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ad o ad o ad ', 'o'\n",
      "'hey\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ad o ad o ad o', ' '\n",
      "'ey\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ad o ad o ad o ', 'a'\n",
      "'y\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ad o ad o ad o a', 'd'\n",
      "'\\xe2\\x80\\x99ve trig o ad o ad o ad o ad o ad o ad o ad o ad', ' '\n",
      "'\\x80\\x99ve trig o ad o ad o ad o ad o ad o ad o ad o ad ', 'o'\n",
      "'\\x99ve trig o ad o ad o ad o ad o ad o ad o ad o ad o', ' '\n",
      "'ve trig o ad o ad o ad o ad o ad o ad o ad o ad o ', 'a'\n",
      "'e trig o ad o ad o ad o ad o ad o ad o ad o ad o a', 'd'\n",
      "' trig o ad o ad o ad o ad o ad o ad o ad o ad o ad', ' '\n",
      "'trig o ad o ad o ad o ad o ad o ad o ad o ad o ad ', 'o'\n",
      "'rig o ad o ad o ad o ad o ad o ad o ad o ad o ad o', ' '\n",
      "'ig o ad o ad o ad o ad o ad o ad o ad o ad o ad o ', 'a'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [00:00<00:00, 64.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'g o ad o ad o ad o ad o ad o ad o ad o ad o ad o a', 'd'\n",
      "' o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad', ' '\n",
      "'o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad ', 'o'\n",
      "' ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o', ' '\n",
      "'ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ', 'a'\n",
      "'d o ad o ad o ad o ad o ad o ad o ad o ad o ad o a', 'd'\n",
      "' o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad', ' '\n",
      "'o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad ', 'o'\n",
      "' ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o', ' '\n",
      "'ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ', 'a'\n",
      "'d o ad o ad o ad o ad o ad o ad o ad o ad o ad o a', 'd'\n",
      "' o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad', ' '\n",
      "'o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad ', 'o'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [00:01<00:00, 79.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o', ' '\n",
      "'ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ', 'a'\n",
      "'d o ad o ad o ad o ad o ad o ad o ad o ad o ad o a', 'd'\n",
      "' o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad', ' '\n",
      "'o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad ', 'o'\n",
      "' ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o', ' '\n",
      "'ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ', 'a'\n",
      "'d o ad o ad o ad o ad o ad o ad o ad o ad o ad o a', 'd'\n",
      "' o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad', ' '\n",
      "'o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad ', 'o'\n",
      "' ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o', ' '\n",
      "'ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ', 'a'\n",
      "'d o ad o ad o ad o ad o ad o ad o ad o ad o ad o a', 'd'\n",
      "' o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad', ' '\n",
      "'o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad ', 'o'\n",
      "' ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o', ' '\n",
      "'ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ', 'a'\n",
      "'d o ad o ad o ad o ad o ad o ad o ad o ad o ad o a', 'd'\n",
      "' o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad', ' '\n",
      "'o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad ', 'o'\n",
      "' ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o', ' '\n",
      "'ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ', 'a'\n",
      "'d o ad o ad o ad o ad o ad o ad o ad o ad o ad o a', 'd'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 78.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad', ' '\n",
      "'o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad ', 'o'\n",
      "' ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o', ' '\n",
      "'ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ', 'a'\n",
      "'d o ad o ad o ad o ad o ad o ad o ad o ad o ad o a', 'd'\n",
      "' o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad', ' '\n",
      "'o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad ', 'o'\n",
      "' ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o', ' '\n",
      "'ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ', 'a'\n",
      "'d o ad o ad o ad o ad o ad o ad o ad o ad o ad o a', 'd'\n",
      "' o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad', ' '\n",
      "'o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad ', 'o'\n",
      "' ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o', ' '\n",
      "'ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ', 'a'\n",
      "o the most intelligent thing…after they’ve trig o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o ad o a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Build initial seed string\n",
    "i = np.random.randint(0, 5000)\n",
    "seed_string = raw_input_string[i:(i+50)]\n",
    "#print repr(seed_string)\n",
    "\n",
    "# Loop throught the following steps:\n",
    "# 1. Grab the last 50 characters\n",
    "# 2. Predict and append the next letter\n",
    "# 3. Repeat steps 1-2 until the limit is reached\n",
    "for i in tqdm(range(n_chars)):\n",
    "    # Encode last 50 characters of seed string\n",
    "    new_seed = seed_string[-50:]\n",
    "    enc_seed = np.array([encode_string(new_seed)]) # transform into shape=[1, 50, 91]\n",
    "\n",
    "    # Predict using seed string\n",
    "    pred_index = op_pred_char.eval(feed_dict={x:enc_seed}, session=sess)\n",
    "    char_vec = np.zeros([1, enc_seed.shape[2]])\n",
    "    char_vec[0][pred_index] = 1\n",
    "    pred_char = decode_string(char_vec)\n",
    "    \n",
    "    # Print last 50 chars and predicted char\n",
    "    print \"{}, {}\".format(repr(new_seed), repr(pred_char))\n",
    "\n",
    "    # Decode and append the character to the end of the seed string\n",
    "    seed_string+=pred_char\n",
    "    \n",
    "# What's the final string?\n",
    "print seed_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
